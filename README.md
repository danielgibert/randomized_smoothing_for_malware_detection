# Towards a Practical Defense against Adversarial Attacks on Deep Learning-based Malware Detectors via Randomized Smoothing

This is the code implementing our approach for the paper 
["Towards a Practical Defense against Adversarial Attacks on
Deep Learning-based Malware Detectors via Randomized Smoothing"](https://arxiv.org/abs/2308.08906), presented at the Workshop of Security and Artiificial Intelligence (SECAI'23),
collocated with the 28th European Symposium on Research in Computer Security (ESORICS'23).

## Summary

Here are the main highlights of our paper:
* Robust Malware Detector: We introduce a novel approach to enhance the robustness of static end-to-end malware detection models via randomized smoothing.
* Adversarial Defense: Our method increases the detection accuracy against adversarial attacks that manipulate malware executables, making it harder for attackers to evade detection.
* Experimental Results: We provide empirical evidence of the effectiveness of our approach against state-of-the-art evasion attacks.

## Dependencies
All models have been trained with PyTorch.

## Collaborators and Funding
A huge thanks to my co-authors, Giulio Zizzo from IBM Research Europe and Quan Le from CeADAR, Ireland's Centre for 
Artificial Intelligence. In addition I would also like to thank Enterprise Ireland for funding this work under the Marie Sklodowska Curie Career Fit PLUS grant.


