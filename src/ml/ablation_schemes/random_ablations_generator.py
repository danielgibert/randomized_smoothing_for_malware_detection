import torch
from typing import Tuple
import random
import math
from random import randint
from src.ml.ablation_schemes.ablations_generator import AblatedEnd2EndGenerator


class RandomAblatedEnd2EndGenerator(AblatedEnd2EndGenerator):
    def __init__(self, train_mode: bool = True, file_portion: float = 0.1, num_chunks: int = 100,
                 padding_value: float = 0.0):
        super().__init__(train_mode)
        self.file_portion = file_portion
        self.padding_value = padding_value
        self.num_chunks = num_chunks

    def create_mask(self, x: torch.Tensor, mask_value_prob: float) -> torch.Tensor:
        mask = torch.rand(x.shape[0]) <= mask_value_prob
        return mask

    def generate_training_chunks(self, batch: list) -> Tuple[torch.Tensor, torch.Tensor]:
        vecs = []
        labels = []
        for x, y in batch:
            # Get mask
            mask_value_prob = 1.0 - self.file_portion
            mask = self.create_mask(x, mask_value_prob)
            # Apply mask - Convert masked elements to self.padding_value
            masked_x = x.masked_fill(mask, self.padding_value)
            vecs.append(masked_x)
            labels.append(y)
        x = torch.nn.utils.rnn.pad_sequence(vecs, batch_first=True, padding_value=self.padding_value)
        # stack will give us (B, 1), so index [:,0] to get to just (B)
        y = torch.stack(labels)[:, 0]

        return x, y

    def generate_testing_chunks(self, batch: list) -> Tuple[torch.Tensor, torch.Tensor]:
        labels = []
        vecs = []
        if len(batch) == 1:  # Only implemented for batch sizes equals to 1
            x = batch[0][0]
            for i in range(self.num_chunks):
                # Get mask
                mask_value_prob = 1.0 - self.file_portion
                mask = self.create_mask(x, mask_value_prob)
                # Apply mask - Convert masked elements to self.padding_value
                masked_x = x.masked_fill(mask, self.padding_value)
                vecs.append(masked_x)
            x = torch.nn.utils.rnn.pad_sequence(vecs, batch_first=True, padding_value=self.padding_value)
            labels.append(batch[0][1])
            y = torch.stack(labels)[:, 0]
            return x, y
        else:
            raise NotImplementedError

    def generate_ablated_versions(self, x: torch.Tensor) -> Tuple[torch.Tensor, list]:
        """
        vecs = []
        for i in range(self.num_chunks):
            # Get mask
            mask_value_prob = 1.0 - self.file_portion
            mask = self.create_mask(x, mask_value_prob)
            # Apply mask - Convert masked elements to self.padding_value
            masked_x = x.masked_fill(mask, self.padding_value)
            vecs.append(masked_x)
        x = torch.nn.utils.rnn.pad_sequence(vecs, batch_first=True, padding_value=self.padding_value)
        return x, None
        """
        mask_value_prob = 1.0 - self.file_portion
        masks = [self.create_mask(x, mask_value_prob) for _ in range(self.num_chunks)]
        masked_x = x.masked_fill(torch.stack(masks), self.padding_value)
        vecs = torch.nn.utils.rnn.pad_sequence(
            [masked_x],
            batch_first=True,
            padding_value=self.padding_value
        )
        x = torch.squeeze(vecs, dim=0)
        return x, None